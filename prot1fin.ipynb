{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os, csv, string, re\n",
    "\n",
    "def cleanup(text):\n",
    "    punctuation = '[!-.:?;@/…|⠀_=♥️\"]' # Note que os sinais [] são delimitadores de um conjunto.\n",
    "    pattern = re.compile(punctuation)\n",
    "    text_subbed = re.sub(pattern, '', text)\n",
    "    text_s = re.sub(r\"http\\S+\", \"\", text_subbed)\n",
    "    ttt = re.sub(r'''((?:https?://|www\\d{0,3}[.]|[a-z0-9.-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|(([^\\s()<>]+|(([^\\s()<>]+)))))+(?:(([^\\s()<>]+|(([^\\s()<>]+))))|[^\\s`!()[]{};:'\".,<>?«»“”‘’]))''', \" \", text_s)\n",
    "    return ttt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevância</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nunca vi um mercado tão cheio</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @folha: guedes diz que vai acionar stf cont...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>deixando tudo mais barato:\\ncupom ifood (app) ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rt @reporterlacerda: inovação no grenal\\n\\npre...</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@ericat_lol mercado a vista vai ficar parado p...</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num                                        Treinamento   relevância\n",
       "0    0                      nunca vi um mercado tão cheio  Irrelevante\n",
       "1    1  rt @folha: guedes diz que vai acionar stf cont...    Relevante\n",
       "2    2  deixando tudo mais barato:\\ncupom ifood (app) ...  Irrelevante\n",
       "3    3  rt @reporterlacerda: inovação no grenal\\n\\npre...  Irrelevante\n",
       "4    4  @ericat_lol mercado a vista vai ficar parado p...    Relevante"
      ]
     },
     "execution_count": 414,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Classificando como categoria #Níveis da categoria\n",
    "dados = pd.read_excel('t1.xlsx')\n",
    "dados.loc[:,'relevância'] = dados['relevância'].astype('category')\n",
    "dados.relevância.cat.categories = ['Irrelevante', 'Relevante']\n",
    "dados.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_r = dados[dados.relevância == 'Relevante']\n",
    "l_ttr = dados_r.Treinamento.tolist()\n",
    "#pra cada palavra na lista do tt, vai criar uma lista só com todas as palavras\n",
    "l_ttr_split = []\n",
    "for i in l_ttr:\n",
    "    l_ttr_split.append(i.split())\n",
    "\n",
    "output=open('prt_rel.txt','w',encoding=\"utf-8-sig\")\n",
    "#lista com palavras limpas\n",
    "lpal_r = []\n",
    "for lista in l_ttr_split:\n",
    "    for pal in lista:\n",
    "        c_pal = cleanup(pal)\n",
    "        if c_pal != \"\":\n",
    "            lpal_r.append(c_pal)\n",
    "\n",
    "s_relev = pd.Series(lpal_r)\n",
    "t_relev = s_relev.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "dados_i = dados[dados.relevância == 'Irrelevante']\n",
    "\n",
    "#tt em lista \n",
    "l_tti = dados_i.Treinamento.tolist()\n",
    "\n",
    "#pra cada palavra na lista do tt, vai criar uma lista só com todas as palavras\n",
    "l_tti_split = []\n",
    "for i in l_tti:\n",
    "    l_tti_split.append(i.split())\n",
    "\n",
    "output=open('prt_i.txt','w',encoding=\"utf-8-sig\")\n",
    "#lista com palavras limpas\n",
    "lpal_i = []\n",
    "for lista in l_tti_split:\n",
    "    for pal in lista:\n",
    "        c_pal = cleanup(pal)\n",
    "        if c_pal != \"\":\n",
    "            lpal_i.append(c_pal)\n",
    "            \n",
    "s_ire = pd.Series(lpal_i)\n",
    "t_ire = s_ire.value_counts(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in dados.num:\n",
    "    lpal_i_temp = lpal_i\n",
    "    lpal_r_temp = lpal_r\n",
    "    tt = dados.iloc[i,1] #pegou o tt inteiro\n",
    "    tt_split = tt.split() #splitou o tt, agora é uma lista com cada elemento sendo uma palavra\n",
    "    frase = []\n",
    "    for pal in tt_split:\n",
    "        frase.append(cleanup(pal)) #cada elemento de frase é uma palavra do tweet já limpa\n",
    "        \n",
    "    #smoothing\n",
    "    for plvr in frase:\n",
    "        if plvr not in lpal_i_temp:\n",
    "            lpal_i_temp.append(plvr)\n",
    "        if plvr not in lpal_r_temp:\n",
    "            lpal_r_temp.append(plvr)\n",
    "\n",
    "    #atualiza séries e tabela\n",
    "    s_relev_temp = pd.Series(lpal_r_temp)\n",
    "    t_relev_temp = s_relev_temp.value_counts(True)\n",
    "    \n",
    "    s_ire_temp = pd.Series(lpal_i_temp)\n",
    "    t_ire_temp = s_ire_temp.value_counts(True)\n",
    "    \n",
    "    #total palavras\n",
    "    portug = lpal_i_temp + lpal_r_temp\n",
    "    s_prtg_temp = pd.Series(portug)\n",
    "    \n",
    "    #calcula probabilidade pelo numero de palavras\n",
    "    p_relev = len(s_relev_temp)/len(s_prtg_temp)\n",
    "    p_irrelev = len(s_ire_temp)/len(s_prtg_temp)\n",
    "\n",
    "    try:\n",
    "        pf_dado_r = t_relev_temp[frase].prod()\n",
    "        pf_dado_i = t_ire_temp[frase].prod()\n",
    "\n",
    "        pr_dado_f = pf_dado_r * p_relev\n",
    "        pi_dado_f = pf_dado_i * p_irrelev\n",
    "        \n",
    "        if pr_dado_f > pi_dado_f:\n",
    "            if (pr_dado_f > pi_dado_f):\n",
    "                dados.loc[dados.num==i,'Classificador'] = 'Relevante'\n",
    "        else:\n",
    "            dados.loc[dados.num==i,'Classificador'] = 'Irrelevante'     \n",
    "            \n",
    "    except:\n",
    "        print(\"erro frase \")\n",
    "        print(frase)\n",
    "        print('')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num</th>\n",
       "      <th>Treinamento</th>\n",
       "      <th>relevância</th>\n",
       "      <th>Classificador</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>nunca vi um mercado tão cheio</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @folha: guedes diz que vai acionar stf cont...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>deixando tudo mais barato:\\ncupom ifood (app) ...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>rt @reporterlacerda: inovação no grenal\\n\\npre...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>@ericat_lol mercado a vista vai ficar parado p...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>295</th>\n",
       "      <td>295</td>\n",
       "      <td>@santosgxbx a expectativa é essa, porém na rea...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>296</th>\n",
       "      <td>296</td>\n",
       "      <td>rt @folha_mercado: guedes diz que vai acionar ...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>297</td>\n",
       "      <td>dólar sobe, o brasileiro médio imediatamente u...</td>\n",
       "      <td>Relevante</td>\n",
       "      <td>Relevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>298</th>\n",
       "      <td>298</td>\n",
       "      <td>rt @vinisantucci: fui ao mercado comprar café\\...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>299</td>\n",
       "      <td>@estherlisboam é terek, pren pren vai faltar a...</td>\n",
       "      <td>Irrelevante</td>\n",
       "      <td>Irrelevante</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>300 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     num                                        Treinamento   relevância  \\\n",
       "0      0                      nunca vi um mercado tão cheio  Irrelevante   \n",
       "1      1  rt @folha: guedes diz que vai acionar stf cont...    Relevante   \n",
       "2      2  deixando tudo mais barato:\\ncupom ifood (app) ...  Irrelevante   \n",
       "3      3  rt @reporterlacerda: inovação no grenal\\n\\npre...  Irrelevante   \n",
       "4      4  @ericat_lol mercado a vista vai ficar parado p...    Relevante   \n",
       "..   ...                                                ...          ...   \n",
       "295  295  @santosgxbx a expectativa é essa, porém na rea...  Irrelevante   \n",
       "296  296  rt @folha_mercado: guedes diz que vai acionar ...    Relevante   \n",
       "297  297  dólar sobe, o brasileiro médio imediatamente u...    Relevante   \n",
       "298  298  rt @vinisantucci: fui ao mercado comprar café\\...  Irrelevante   \n",
       "299  299  @estherlisboam é terek, pren pren vai faltar a...  Irrelevante   \n",
       "\n",
       "    Classificador  \n",
       "0     Irrelevante  \n",
       "1       Relevante  \n",
       "2     Irrelevante  \n",
       "3     Irrelevante  \n",
       "4       Relevante  \n",
       "..            ...  \n",
       "295   Irrelevante  \n",
       "296     Relevante  \n",
       "297     Relevante  \n",
       "298   Irrelevante  \n",
       "299   Irrelevante  \n",
       "\n",
       "[300 rows x 4 columns]"
      ]
     },
     "execution_count": 428,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
